{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jeremy-su1/ai-algorithm/blob/main/DATASET_stackExchange%2Bmultilable.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "8LWJINNGMtO5",
        "outputId": "42a0be4a-6a9e-49a2-d167-b1e7605da678",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from ast import literal_eval\n",
        "\n",
        "# 공통 경로 설정\n",
        "base_path = '/content/drive/MyDrive/ML/AI-algorithm/dataset'\n",
        "\n",
        "# 데이터셋 파일 경로\n",
        "biology_path = f'{base_path}/biology.csv'\n",
        "cooking_path = f'{base_path}/cooking.csv'\n",
        "diy_path = f'{base_path}/diy.csv'\n",
        "travel_path = f'{base_path}/travel.csv'\n",
        "stackoverflow_train_path = f'{base_path}/rev_tag_training_samples.csv'\n",
        "stackoverflow_test_path = f'{base_path}/rev_tag_test_samples.csv'\n",
        "\n",
        "# 데이터셋 로드 및 title과 content 결합\n",
        "biology = pd.read_csv(biology_path)\n",
        "biology['title_content'] = biology['title'] + ' ' + biology['content']\n",
        "\n",
        "cooking = pd.read_csv(cooking_path)\n",
        "cooking['title_content'] = cooking['title'] + ' ' + cooking['content']\n",
        "\n",
        "diy = pd.read_csv(diy_path)\n",
        "diy['title_content'] = diy['title'] + ' ' + diy['content']\n",
        "\n",
        "travel = pd.read_csv(travel_path)\n",
        "travel['title_content'] = travel['title'] + ' ' + travel['content']\n",
        "\n",
        "stackoverflow_train = pd.read_csv(stackoverflow_train_path)\n",
        "stackoverflow_train['title_content'] = stackoverflow_train['Title'] + ' ' + stackoverflow_train['Body']\n",
        "\n",
        "stackoverflow_val = pd.read_csv(stackoverflow_test_path)\n",
        "stackoverflow_val['title_content'] = stackoverflow_val['Title'] + ' ' + stackoverflow_val['Body']\n",
        "\n",
        "# 레이블 할당\n",
        "labels = {\n",
        "    'biology': 0,\n",
        "    'cooking': 1,\n",
        "    'diy': 2,\n",
        "    'travel': 3,\n",
        "    'stackoverflow': 4\n",
        "}\n",
        "\n",
        "# StackOverflow 데이터의 고유 sub_label 추출 및 인덱스 부여\n",
        "unique_tags = set()\n",
        "for tags in stackoverflow_train['Tags_new'].dropna():\n",
        "    unique_tags.update(literal_eval(tags))\n",
        "\n",
        "for tags in stackoverflow_val['Tags_new'].dropna():\n",
        "    unique_tags.update(literal_eval(tags))\n",
        "\n",
        "unique_tags = sorted(list(unique_tags))  # 태그를 정렬하여 고유 인덱스 할당\n",
        "tag2id = {tag: idx for idx, tag in enumerate(unique_tags)}\n",
        "\n",
        "# sub_label을 멀티라벨 인덱스 리스트로 변환\n",
        "def encode_sub_label(tags):\n",
        "    tags = literal_eval(tags) if isinstance(tags, str) else []\n",
        "    return [tag2id[tag] for tag in tags if tag in tag2id]\n",
        "\n",
        "stackoverflow_train['sub_label'] = stackoverflow_train['Tags_new'].apply(encode_sub_label)\n",
        "stackoverflow_val['sub_label'] = stackoverflow_val['Tags_new'].apply(encode_sub_label)\n",
        "\n",
        "# 데이터셋을 나누고 레이블을 할당하는 함수\n",
        "def split_and_label(dataset, label, validation_size=400, train_size=2000, sublabel=False):\n",
        "    validation_data = dataset.sample(n=min(validation_size, len(dataset)), random_state=1)\n",
        "    train_data = dataset.drop(validation_data.index).sample(n=min(train_size, len(dataset) - len(validation_data)), random_state=1)\n",
        "    validation_data['label'] = label\n",
        "    train_data['label'] = label\n",
        "\n",
        "    if sublabel:\n",
        "        return train_data[['title_content', 'label', 'sub_label']], validation_data[['title_content', 'label', 'sub_label']]\n",
        "    else:\n",
        "        return train_data[['title_content', 'label']], validation_data[['title_content', 'label']]\n",
        "\n",
        "# 데이터셋을 나누고 레이블을 할당\n",
        "biology_train, biology_val = split_and_label(biology, labels['biology'])\n",
        "cooking_train, cooking_val = split_and_label(cooking, labels['cooking'])\n",
        "diy_train, diy_val = split_and_label(diy, labels['diy'])\n",
        "travel_train, travel_val = split_and_label(travel, labels['travel'])\n",
        "\n",
        "# StackOverflow 데이터는 이미 나누어져 있으므로 바로 레이블 할당\n",
        "stackoverflow_train['label'] = labels['stackoverflow']\n",
        "stackoverflow_val['label'] = labels['stackoverflow']\n",
        "\n",
        "# 훈련 데이터셋과 검증 데이터셋을 각각 하나로 합치기\n",
        "combined_train_dataset = pd.concat([biology_train, cooking_train, diy_train, travel_train, stackoverflow_train[['title_content', 'label', 'sub_label']]], ignore_index=True)\n",
        "combined_val_dataset = pd.concat([biology_val, cooking_val, diy_val, travel_val, stackoverflow_val[['title_content', 'label', 'sub_label']]], ignore_index=True)\n",
        "\n",
        "# sub_label을 문자열로 변환하고, NaN을 빈 문자열로 대체\n",
        "combined_train_dataset['sub_label'] = combined_train_dataset['sub_label'].fillna('').apply(lambda x: str(x) if x else '')\n",
        "combined_val_dataset['sub_label'] = combined_val_dataset['sub_label'].fillna('').apply(lambda x: str(x) if x else '')\n",
        "\n",
        "# 데이터셋 확인 (저장 전 샘플 확인)\n",
        "print(\"Train dataset sample:\")\n",
        "print(combined_train_dataset.sample(5))\n",
        "print(\"\\nValidation dataset sample:\")\n",
        "print(combined_val_dataset.sample(5))\n",
        "\n",
        "# 결과 데이터셋을 CSV 파일로 저장하기\n",
        "train_csv_path = f'{base_path}/stackexchange_train_dataset.csv'\n",
        "val_csv_path = f'{base_path}/stackexchange_val_dataset.csv'\n",
        "combined_train_dataset.to_csv(train_csv_path, index=False)\n",
        "combined_val_dataset.to_csv(val_csv_path, index=False)\n",
        "\n",
        "print(f\"\\nTrain dataset saved to {train_csv_path}\")\n",
        "print(f\"Validation dataset saved to {val_csv_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTZdVrK5sMvL",
        "outputId": "9e7d40dd-c25e-4e11-c842-97b405a23390"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset sample:\n",
            "                                           title_content  label sub_label\n",
            "1245   What triggers creative thought in humans? <p>C...      0          \n",
            "27079  What is the difference between Expo CLI and Re...      4       [8]\n",
            "8111   How to check JSP varilable and hide if value i...      4       [0]\n",
            "23881  Return first letter of each word capitalized |...      4       [7]\n",
            "12099  Using php in python language is really a good ...      4    [2, 1]\n",
            "\n",
            "Validation dataset sample:\n",
            "                                          title_content  label sub_label\n",
            "3458  when i use \"=\" copy a object ,why source value...      4       [0]\n",
            "3042  Cross origin error in jquery.load() <p>I want ...      4       [5]\n",
            "3748  C# Use textbox value in another cs file I'd li...      4    [7, 4]\n",
            "1534  How to find car rental companies in Kalibo, Ph...      3          \n",
            "2210  Convert an int** array into a char** array of ...      4    [2, 7]\n",
            "\n",
            "Train dataset saved to /content/drive/MyDrive/ML/AI-algorithm/dataset/stackexchange_train_dataset.csv\n",
            "Validation dataset saved to /content/drive/MyDrive/ML/AI-algorithm/dataset/stackexchange_val_dataset.csv\n"
          ]
        }
      ]
    }
  ]
}