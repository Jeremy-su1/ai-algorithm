{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPBV2CCo/+4eQEpEr8MeJ6Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jeremy-su1/ai-algorithm/blob/main/jihyun_llama_1b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Settings"
      ],
      "metadata": {
        "id": "OE8G8FFW4jd7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Puz0vcE4cnv"
      },
      "outputs": [],
      "source": [
        "!pip install datasets\n",
        "!pip install transformers[torch]\n",
        "!pip install peft"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "DPEOTT8W43-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Model"
      ],
      "metadata": {
        "id": "UE62LdFp7ioI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "model_id = \"meta-llama/Llama-3.2-1B-Instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "# Add the padding token to the tokenizer\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
        "# If you are using the model for training, also resize the model embeddings to include the padding token\n",
        "model.resize_token_embeddings(len(tokenizer))\n"
      ],
      "metadata": {
        "id": "Uj0yw1Gz4u83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Dataset load, 전처리"
      ],
      "metadata": {
        "id": "GKteIPni7lgj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from datasets import load_dataset\n",
        "import kagglehub\n",
        "\n",
        "# Kaggle에서 Stack Overflow 데이터셋 다운로드\n",
        "path = kagglehub.dataset_download(\"imoore/60k-stack-overflow-questions-with-quality-rate\")\n",
        "\n",
        "# train.csv 파일 찾기\n",
        "train_file = None\n",
        "files = os.listdir(path)\n",
        "for file in files:\n",
        "    if 'train.csv' in file:\n",
        "        train_file = os.path.join(path, file)\n",
        "        break\n",
        "\n",
        "# 데이터셋 로드\n",
        "if train_file:\n",
        "    train_dataset = load_dataset('csv', data_files=train_file)\n",
        "else:\n",
        "    print(\"train.csv 파일을 찾을 수 없습니다.\")\n",
        "\n",
        "# 'body'와 'tags' 열 추출\n",
        "def preprocess_function(examples):\n",
        "    return {'input_text': examples['Body'], 'labels': examples['Tags']}\n",
        "\n",
        "train_dataset = train_dataset['train'].map(preprocess_function)\n"
      ],
      "metadata": {
        "id": "0Fc9alh4567B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Tokenizing"
      ],
      "metadata": {
        "id": "hK8BPF697oyj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. tran data loader"
      ],
      "metadata": {
        "id": "hWAfMMZQ7ukD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Train"
      ],
      "metadata": {
        "id": "3kvqtpur7yYx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Model 학습이 끝난 모델 저장"
      ],
      "metadata": {
        "id": "4eFOEvQ270Pk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습이 끝나면 모델과 토크나이저 저장\n",
        "model.save_pretrained(\"./fine_tuned_llama\")\n",
        "tokenizer.save_pretrained(\"./fine_tuned_llama\")\n"
      ],
      "metadata": {
        "id": "M0f3iSwz72PB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. 모델 평가"
      ],
      "metadata": {
        "id": "kut1J0T274pf"
      }
    }
  ]
}