{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1evQ3jpbAJkUhHcugxKTwdinyW12M8dJq",
      "authorship_tag": "ABX9TyOfEtoB4g0gj6AQ/xzhQ4A9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jeremy-su1/ai-algorithm/blob/main/datasets/DATASET_stackExchange.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 데이터셋 파일 경로\n",
        "biology_path = '/content/drive/MyDrive/LLMEmbed/biology.csv'\n",
        "cooking_path = '/content/drive/MyDrive/LLMEmbed/cooking.csv'\n",
        "diy_path = '/content/drive/MyDrive/LLMEmbed/diy.csv'\n",
        "travel_path = '/content/drive/MyDrive/LLMEmbed/travel.csv'\n",
        "stackoverflow_path = '/content/drive/MyDrive/LLMEmbed/MultiLabel/rev_tag_training_samples.csv'\n",
        "\n",
        "# 데이터셋 로드\n",
        "biology = pd.read_csv(biology_path)\n",
        "cooking = pd.read_csv(cooking_path)\n",
        "diy = pd.read_csv(diy_path)\n",
        "travel = pd.read_csv(travel_path)\n",
        "stackoverflow = pd.read_csv(stackoverflow_path)\n",
        "\n",
        "# title_content 컬럼 생성\n",
        "biology['title_content'] = biology['title']\n",
        "cooking['title_content'] = cooking['title']\n",
        "diy['title_content'] = diy['title']\n",
        "travel['title_content'] = travel['title']\n",
        "stackoverflow['title_content'] = stackoverflow['Title']\n",
        "\n",
        "# 레이블 할당\n",
        "labels = {\n",
        "    'biology': 0,\n",
        "    'cooking': 1,\n",
        "    'diy': 2,\n",
        "    'travel': 3,\n",
        "    'stackoverflow': 4\n",
        "}\n",
        "\n",
        "# 데이터셋을 나누고 레이블을 할당하는 함수\n",
        "def split_and_label(dataset, label, validation_size=200, train_size=2000, test_size=200, additional_columns=None):\n",
        "    additional_columns = additional_columns or []\n",
        "\n",
        "    # 검증 데이터셋 추출\n",
        "    validation_data = dataset.sample(n=min(validation_size, len(dataset)), random_state=1)\n",
        "    # 남은 데이터 중에서 테스트 데이터셋 추출\n",
        "    remaining_data = dataset.drop(validation_data.index)\n",
        "    test_data = remaining_data.sample(n=min(test_size, len(remaining_data)), random_state=2)\n",
        "    # 남은 데이터 중에서 훈련 데이터셋 추출\n",
        "    train_data = remaining_data.drop(test_data.index).sample(n=min(train_size, len(remaining_data) - len(test_data)), random_state=1)\n",
        "\n",
        "    # 레이블 추가\n",
        "    validation_data['label'] = label\n",
        "    test_data['label'] = label\n",
        "    train_data['label'] = label\n",
        "\n",
        "    # 필요한 컬럼만 선택\n",
        "    validation_data = validation_data[['title_content', 'label'] + additional_columns]\n",
        "    test_data = test_data[['title_content', 'label'] + additional_columns]\n",
        "    train_data = train_data[['title_content', 'label'] + additional_columns]\n",
        "\n",
        "    return train_data, validation_data, test_data\n",
        "\n",
        "# split_and_label 함수 호출시 추가 컬럼들을 포함하도록 합니다\n",
        "additional_columns = ['Tags_new', 'Algorithms', 'Backend', 'Data Science', 'Databases', 'Dev Tools', 'Frontend', 'Mobile', 'Systems', 'iOS/macOS']  # StackOverflow 데이터셋에 있는 추가 컬럼 이름\n",
        "biology_train, biology_val, biology_test = split_and_label(biology, labels['biology'])\n",
        "cooking_train, cooking_val, cooking_test = split_and_label(cooking, labels['cooking'])\n",
        "diy_train, diy_val, diy_test = split_and_label(diy, labels['diy'])\n",
        "travel_train, travel_val, travel_test = split_and_label(travel, labels['travel'])\n",
        "stackoverflow_train, stackoverflow_val, stackoverflow_test = split_and_label(stackoverflow, labels['stackoverflow'], additional_columns=additional_columns)\n",
        "\n",
        "# 훈련, 검증, 테스트 데이터셋을 각각 하나로 합치기\n",
        "combined_train_dataset = pd.concat([biology_train, cooking_train, diy_train, travel_train, stackoverflow_train], ignore_index=True)\n",
        "combined_val_dataset = pd.concat([biology_val, cooking_val, diy_val, travel_val, stackoverflow_val], ignore_index=True)\n",
        "combined_test_dataset = pd.concat([biology_test, cooking_test, diy_test, travel_test, stackoverflow_test], ignore_index=True)\n",
        "\n",
        "# 결과 데이터셋을 CSV 파일로 저장하기\n",
        "train_csv_path = '/content/drive/MyDrive/LLMEmbed/dataset/stackexchange_train_dataset_10000_title.csv'\n",
        "val_csv_path = '/content/drive/MyDrive/LLMEmbed/dataset/stackexchange_val_dataset_1000_title.csv'\n",
        "test_csv_path = '/content/drive/MyDrive/LLMEmbed/dataset/stackexchange_test_dataset_1000_title.csv'\n",
        "combined_train_dataset.to_csv(train_csv_path, index=False)\n",
        "combined_val_dataset.to_csv(val_csv_path, index=False)\n",
        "combined_test_dataset.to_csv(test_csv_path, index=False)\n",
        "\n",
        "print(f\"Train dataset saved to {train_csv_path}\")\n",
        "print(f\"Validation dataset saved to {val_csv_path}\")\n",
        "print(f\"Test dataset saved to {test_csv_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7eVot0B1wwW",
        "outputId": "e304235a-875b-46a4-b2ed-abb1b6255e70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset saved to /content/drive/MyDrive/LLMEmbed/dataset/stackexchange_train_dataset_10000_title.csv\n",
            "Validation dataset saved to /content/drive/MyDrive/LLMEmbed/dataset/stackexchange_val_dataset_1000_title.csv\n",
            "Test dataset saved to /content/drive/MyDrive/LLMEmbed/dataset/stackexchange_test_dataset_1000_title.csv\n"
          ]
        }
      ]
    }
  ]
}